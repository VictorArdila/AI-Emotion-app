---Configuracion---
> Red
  - Convolucional
> Funciones de activacion
  - relu, softmax
> Algorito de entretamiento
  - Adam
> Rata de Aprendizaje
  - 0.0001
> Erro Maximo Permitido
  - 0.0001
> Tipo de red
  - Multicapa
> Numero de capas
 - 12

---Estructura---
> Input Conv2D
  - Filtro:32
  - kernel:(3,3)
  - funcion de activacion:relu
> Agrupacion
  - Tamma単o: (2,2)
  - funcion de activacion:relu
> Conv2D
  - Filtro:64
  - kernel:(3,3)
  - funcion de activacion:relu
> Agrupacion
  - Tamma単o: (2,2)
  - funcion de activacion:relu
> Conv2D
  - Filtro:128
  - kernel:(3,3)
  - funcion de activacion:relu
> Agrupacion
  - Tamma単o: (2,2)
  - funcion de activacion:relu
> Conv2D
  - Filtro:256
  - kernel:(3,3)
  - funcion de activacion:relu
> Agrupacion
  - Tamma単o: (2,2)
  - funcion de activacion:relu
> Flatten
> Oculta1
  - numero de neuronas:100
  - funcion de activacion:relu
> Oculta2
  - numero de neuronas:50
  - funcion de activacion:relu
> Output
  - numero de neuronas:7
  - funcion de activacion:softmax

---Entrenamiento---
> Iteraciones
  - 150000
> Numero de Entrenamientos
  - 150
> EMP de la red
  - 0.0601
